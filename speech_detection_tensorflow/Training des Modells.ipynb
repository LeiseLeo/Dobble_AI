{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12e079f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INFO:\n",
    "# Der Code basiert auf Tensorflow Modulen, und beeinhaltet Funktionen welche in den zur Verfügung gestellten\n",
    "# Beispiel Colabs von Tensorflow zu finden wanren.\n",
    "# Jedoch wurden Änderungen vorgenommen, weswegen der Code nicht 1 zu 1 kopiert werden sollte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7945f97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U -q tensorflow tensorflow_datasets\n",
    "!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2\n",
    "!pip install -U -q tensorflow_addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb4839c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from IPython import display\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ee231e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setzen eines konstanten Seeds um die Auswahl zu reproduzieren \n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a411ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importieren der Trainingsdaten aus privatem Google-Drive Speicher \n",
    "from google.colab import drive\n",
    "import shutil\n",
    "\n",
    "# \"G:\\My Drive\\second_augmented_dataset.zip\"\n",
    "drive.mount('/content/gdrive/', force_remount=True)\n",
    "%cd gdrive/MyDrive/\n",
    "shutil.copy(\"/testing.zip\", \"/content/\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5b6da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"data/speech_commands/dataset\" # Umbenennung des Datenssatz-Ordners in \"dataset\"\n",
    "os.mkdir('/content/data/speech_commands')\n",
    "\n",
    "data_dir = pathlib.Path(DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4947908d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content \n",
    "commands = np.array(tf.io.gfile.listdir(str(data_dir))) # Erstellung einer python list mit allen Symbolnamen \n",
    "print('Commands:', commands)\n",
    "\n",
    "# OUT: ['Ahornblatt' 'Klecks' 'Tropfen' 'Kleeblatt' 'Clown' 'Iglu' 'Hand'\n",
    "#  'Fragezeichen' 'Uhr' 'KДse' 'Flasche' 'Stoppschild' 'SchildkrФte'\n",
    "#  'EiswБrfel' 'Kaktus' 'Kerze' 'Schloss' 'Mond' 'Anker' 'Auto' 'Blitz'\n",
    "#  'Geist' 'NotenschlБssel' 'Katze' 'Baum' 'Drache' 'Spinnennetz' 'Spinne'\n",
    "#  'Vogel' 'Mann' 'Zebra' 'Sonne' 'Ausrufezeichen' 'Schneeflocke' 'Delfin'\n",
    "#  'Apfel' 'Herz' 'MarienkДfer' 'Totenkopf' 'Pferd' 'Auge' 'GlБhbirne'\n",
    "#  'Dino' 'Schneemann' 'Lippen' 'Feuer' 'Stift' 'Bombe' 'Hund' 'YingYang'\n",
    "#  'Schere' 'Hammer' 'Fadenkreuz' 'Blume' 'Karotte' 'SchlБssel' 'background'\n",
    "#  'Brille']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfd2105",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds = tf.keras.utils.audio_dataset_from_directory(\n",
    "    directory=data_dir,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    seed=0,\n",
    "    output_sequence_length=16000,\n",
    "    subset='both')\n",
    "\n",
    "label_names = np.array(train_ds.class_names)\n",
    "print()\n",
    "print(\"label names:\", label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b3570a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion squeeze entfernt die zusätzlichen listen, welche nicht benötigt werden, da die Trainingsdaten nur 1CH besitzen \n",
    "def squeeze(audio, labels):\n",
    "  audio = tf.squeeze(audio, axis=-1)\n",
    "  print(\"audio\", audio)\n",
    "  print(\"labels\",labels)\n",
    "  return audio, labels\n",
    "\n",
    "train_ds = train_ds.map(squeeze, tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.map(squeeze, tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397b23c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aufteilung der Daten in ein Trainings- und Test- Datenset \n",
    "test_ds = val_ds.shard(num_shards=2, index=0)\n",
    "val_ds = val_ds.shard(num_shards=2, index=1)\n",
    "\n",
    "print(train_ds)\n",
    "print(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf6b327",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train_ds.take(1)\", train_ds.take(1))\n",
    "\n",
    "for example_audio, example_labels in train_ds.take(1):  \n",
    "  print(\"example_audio.shape\", example_audio.shape)\n",
    "  print(example_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c00552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konvertiert die Rohdaten (waveform) in ein Spektrogramm mit STFT\n",
    "def get_spectrogram(waveform):\n",
    "  spectrogram = tf.signal.stft(waveform, frame_length=253, frame_step=128)\n",
    "  # Umfang des STFT wird durch absoluten Wert des Tensors berechnet \n",
    "  spectrogram = tf.abs(spectrogram)\n",
    "\n",
    "  # Add a `channels` dimension, so that the spectrogram can be used\n",
    "  # as image-like input data with convolution layers (which expect\n",
    "  # shape (`batch_size`, `height`, `width`, `channels`).\n",
    "  spectrogram = spectrogram[..., tf.newaxis]\n",
    "  return spectrogram\n",
    "\n",
    "# Funktion gibt ein Bild des Spektrogramms zurück  \n",
    "def plot_spectrogram(spectrogram, ax):\n",
    "  if len(spectrogram.shape) > 2:\n",
    "    assert len(spectrogram.shape) == 3\n",
    "    spectrogram = np.squeeze(spectrogram, axis=-1)\n",
    "  # Convert the frequencies to log scale and transpose, so that the time is\n",
    "  # represented on the x-axis (columns).\n",
    "  # Add an epsilon to avoid taking a log of zero.\n",
    "  log_spec = np.log(spectrogram.T + np.finfo(float).eps)\n",
    "  height = log_spec.shape[0]\n",
    "  width = log_spec.shape[1]\n",
    "  X = np.linspace(0, np.size(spectrogram), num=width, dtype=int)\n",
    "  Y = range(height)\n",
    "  ax.pcolormesh(X, Y, log_spec)\n",
    "\n",
    "# Funktion erstellt ein Datenset aus den Spektrogrammen \n",
    "def make_spec_ds(ds):\n",
    "  return ds.map(\n",
    "      map_func=lambda audio,label: (get_spectrogram(audio), label),\n",
    "      num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6baba4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datenset aus Spektrogrammen wird erstellt \n",
    "train_spectrogram_ds = make_spec_ds(train_ds)\n",
    "val_spectrogram_ds = make_spec_ds(val_ds)\n",
    "test_spectrogram_ds = make_spec_ds(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e34cc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unterusuchung von Spektrogramme für verschiedene Beispiele aus dem Datenset\n",
    "print(\"train_spectrogram_ds\", train_spectrogram_ds)\n",
    "for example_spectrograms, example_spect_labels in train_spectrogram_ds.take(1):\n",
    "  break\n",
    "print(\"example_spectrograms\", example_spectrograms)\n",
    "print(\"example_spect_labels\", example_spect_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb33938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduzierung der Latenz beim späteren Trainieren durch vorheriges cachen \n",
    "train_spectrogram_ds = train_spectrogram_ds.cache().shuffle(10000).prefetch(tf.data.AUTOTUNE)\n",
    "val_spectrogram_ds = val_spectrogram_ds.cache().prefetch(tf.data.AUTOTUNE)\n",
    "test_spectrogram_ds = test_spectrogram_ds.cache().prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6307f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellung eines Sequential-Models \n",
    "\n",
    "input_shape = example_spectrograms.shape[1:]\n",
    "print('Input shape:', input_shape)\n",
    "num_labels = len(label_names)\n",
    "print(\"num_labels\", num_labels)\n",
    "\n",
    "# Normalisierung jedes Pixels für seinen  Mittelwert und seiner Standardabweichung\n",
    "norm_layer = layers.Normalization()\n",
    "\n",
    "# Layer werden an die Spektogrammdaten mit .adapt() angepasst \n",
    "norm_layer.adapt(data=train_spectrogram_ds.map(map_func=lambda spec, label: spec))\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=input_shape),\n",
    "    # Downsample the input\n",
    "    layers.Resizing(64, 64),\n",
    "    # Normalize data input\n",
    "    norm_layer,\n",
    "    layers.Conv2D(32, 3, activation='relu'),\n",
    "    layers.Conv2D(64, 3, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(num_labels),\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# OUT:\n",
    "# Input shape: (124, 129, 1)\n",
    "# num_labels 58\n",
    "# Model: \"sequential\"\n",
    "# _________________________________________________________________\n",
    "#  Layer (type)                Output Shape              Param #   \n",
    "# =================================================================\n",
    "#  resizing (Resizing)         (None, 64, 64, 1)         0         \n",
    "                                                                 \n",
    "#  normalization (Normalizatio  (None, 64, 64, 1)        3         \n",
    "#  n)                                                              \n",
    "                                                                 \n",
    "#  conv2d (Conv2D)             (None, 62, 62, 32)        320       \n",
    "                                                                 \n",
    "#  conv2d_1 (Conv2D)           (None, 60, 60, 64)        18496     \n",
    "                                                                 \n",
    "#  max_pooling2d (MaxPooling2D  (None, 30, 30, 64)       0         \n",
    "#  )                                                               \n",
    "                                                                 \n",
    "#  dropout (Dropout)           (None, 30, 30, 64)        0         \n",
    "                                                                 \n",
    "#  flatten (Flatten)           (None, 57600)             0         \n",
    "                                                                 \n",
    "#  dense (Dense)               (None, 128)               7372928   \n",
    "                                                                 \n",
    "#  dropout_1 (Dropout)         (None, 128)               0         \n",
    "                                                                 \n",
    "#  dense_1 (Dense)             (None, 58)                7482      \n",
    "                                                                 \n",
    "# =================================================================\n",
    "# Total params: 7,399,229\n",
    "# Trainable params: 7,399,226\n",
    "# Non-trainable params: 3\n",
    "# _________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c692db77",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d988f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainieren des kompilierten Sequential-Models\n",
    "EPOCHS = 20\n",
    "history = model.fit(\n",
    "    train_spectrogram_ds,\n",
    "    validation_data=val_spectrogram_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=tf.keras.callbacks.EarlyStopping(verbose=1, patience=2),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478542ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auswertung der Daten\n",
    "metrics = history.history\n",
    "print(\"metrics\", metrics)\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.epoch, metrics['loss'], metrics['val_loss'])\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.ylim([0, max(plt.ylim())])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss [CrossEntropy]')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.epoch, 100*np.array(metrics['accuracy']), 100*np.array(metrics['val_accuracy']))\n",
    "plt.legend(['accuracy', 'val_accuracy'])\n",
    "plt.ylim([0, 100])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy [%]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c7f8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExportModel(tf.Module):\n",
    "  def __init__(self, model):\n",
    "    self.model = model\n",
    "\n",
    "    # Accept either a string-filename or a batch of waveforms.\n",
    "    # YOu could add additional signatures for a single wave, or a ragged-batch. \n",
    "    self.__call__.get_concrete_function(\n",
    "        x=tf.TensorSpec(shape=(), dtype=tf.string))\n",
    "    self.__call__.get_concrete_function(\n",
    "       x=tf.TensorSpec(shape=[None, 16000], dtype=tf.float32))\n",
    "\n",
    "\n",
    "  @tf.function\n",
    "  def __call__(self, x):\n",
    "    # If they pass a string, load the file and decode it. \n",
    "    if x.dtype == tf.string:\n",
    "      x = tf.io.read_file(x)\n",
    "      x, _ = tf.audio.decode_wav(x, desired_channels=1, desired_samples=16000,)\n",
    "      x = tf.squeeze(x, axis=-1)\n",
    "      x = x[tf.newaxis, :]\n",
    "    \n",
    "    x = get_spectrogram(x)  \n",
    "    result = self.model(x, training=False)\n",
    "    \n",
    "    class_ids = tf.argmax(result, axis=-1)\n",
    "    class_names = tf.gather(label_names, class_ids)\n",
    "    return {'predictions':result,\n",
    "            'class_ids': class_ids,\n",
    "            'class_names': class_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e284412b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "# Speichern des Modells \n",
    "\n",
    "model_json = model.to_json() # serialize model to JSON\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "model.save_weights(\"model.h5\") # # serialize weights to HDF5\n",
    "print(\"Saved model to disk\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
